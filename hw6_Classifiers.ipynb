{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application of ML Classifiers to Identify Aged Cells\n",
    "\n",
    "During this homework, aged and youthful RBCs will be classified based on DNA methylation profiles.\n",
    "\n",
    "This homework will:\n",
    "\n",
    "* Compare performance of various classification algorithms\n",
    "\n",
    "* Evaluate effects of train/test split on classifier performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for this homework comes from GEO GSE40279: [Hannum, G.; Guinney, J.; Zhao, L.; Zhang, L.; Hughes, G.; Sadda, S.; Klotzle, B.; Bibikova, M.; Fan, J.-B.; Gao, Y.; Deconde, R.; Chen, M.; Rajapakse, I.; Friend, S.; Ideker, T.; Zhang, K. Genome-Wide Methylation Profiles Reveal Quantitative Views of Human Aging Rates. Mol Cell 2013, 49 (2), 359–367.](https://doi.org/10.1016/j.molcel.2012.10.016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statements:\n",
    "\n",
    "1. Plot the age distribution of subjects using a histogram. Add a vertical line to the plot at age 65.\n",
    "\n",
    "2. Label subjects using two groups: \"youthful\" (ages <65) and \"aged\" (ages >=65). This age threshold divides the subjects into two groups of approximately equal size.\n",
    "\n",
    "3. Randomly assign 20% of samples in the data to a training set. Assign the remaining 80% of samples to a test set.\n",
    "\n",
    "4. Train an SVM and logistic regression classifier to predict age labels (\"youthful\" or \"aged\") for subjects in the training set based on CpG methylation levels. **Hint:** When training your SVM classifier, use a linear kernel. \n",
    "\n",
    "5. Evaluate each classifier's performance on the test set by (a) identifying the classifier's accuracy and (b) generating a confusion matrix.\n",
    "\n",
    "6. What is the false positive rate of each classifier? What is the false negative rate?\n",
    "\n",
    "7. Repeat questions 3-6 for a 80%/20% train/test split. How does increasing the training set size affect classifier performance? What considerations would you make when specifying a train/test split?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Blood Cell DNA Methylation Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Data Set: \n",
      "\n",
      "(656, 3231)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cg00320765</th>\n",
       "      <th>cg04223956</th>\n",
       "      <th>cg03407966</th>\n",
       "      <th>cg07403374</th>\n",
       "      <th>cg10122230</th>\n",
       "      <th>cg24603972</th>\n",
       "      <th>cg04105597</th>\n",
       "      <th>cg12613081</th>\n",
       "      <th>cg20169734</th>\n",
       "      <th>cg06012428</th>\n",
       "      <th>...</th>\n",
       "      <th>cg04820440</th>\n",
       "      <th>cg12662162</th>\n",
       "      <th>cg18527971</th>\n",
       "      <th>cg24367761</th>\n",
       "      <th>cg13027280</th>\n",
       "      <th>cg14801864</th>\n",
       "      <th>cg04984575</th>\n",
       "      <th>cg24836583</th>\n",
       "      <th>cg18079534</th>\n",
       "      <th>cg17362351</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM989827</th>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.906154</td>\n",
       "      <td>0.943392</td>\n",
       "      <td>0.945140</td>\n",
       "      <td>0.904783</td>\n",
       "      <td>0.925199</td>\n",
       "      <td>0.939552</td>\n",
       "      <td>0.927781</td>\n",
       "      <td>0.907609</td>\n",
       "      <td>0.562828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905512</td>\n",
       "      <td>0.113116</td>\n",
       "      <td>0.862678</td>\n",
       "      <td>0.920586</td>\n",
       "      <td>0.918897</td>\n",
       "      <td>0.388287</td>\n",
       "      <td>0.492888</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.879088</td>\n",
       "      <td>0.929998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM989828</th>\n",
       "      <td>0.811994</td>\n",
       "      <td>0.883670</td>\n",
       "      <td>0.937935</td>\n",
       "      <td>0.938376</td>\n",
       "      <td>0.929686</td>\n",
       "      <td>0.930090</td>\n",
       "      <td>0.945331</td>\n",
       "      <td>0.927932</td>\n",
       "      <td>0.889046</td>\n",
       "      <td>0.494344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.858246</td>\n",
       "      <td>0.086961</td>\n",
       "      <td>0.839228</td>\n",
       "      <td>0.907824</td>\n",
       "      <td>0.893503</td>\n",
       "      <td>0.302853</td>\n",
       "      <td>0.481399</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>0.887265</td>\n",
       "      <td>0.920493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM989829</th>\n",
       "      <td>0.771808</td>\n",
       "      <td>0.893670</td>\n",
       "      <td>0.947600</td>\n",
       "      <td>0.915895</td>\n",
       "      <td>0.914621</td>\n",
       "      <td>0.917694</td>\n",
       "      <td>0.953757</td>\n",
       "      <td>0.901260</td>\n",
       "      <td>0.905771</td>\n",
       "      <td>0.538240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890826</td>\n",
       "      <td>0.124099</td>\n",
       "      <td>0.868137</td>\n",
       "      <td>0.891428</td>\n",
       "      <td>0.899440</td>\n",
       "      <td>0.372548</td>\n",
       "      <td>0.510238</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.899792</td>\n",
       "      <td>0.936039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM989830</th>\n",
       "      <td>0.800116</td>\n",
       "      <td>0.905407</td>\n",
       "      <td>0.930441</td>\n",
       "      <td>0.922973</td>\n",
       "      <td>0.891672</td>\n",
       "      <td>0.923459</td>\n",
       "      <td>0.951738</td>\n",
       "      <td>0.899530</td>\n",
       "      <td>0.881363</td>\n",
       "      <td>0.533346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902694</td>\n",
       "      <td>0.087692</td>\n",
       "      <td>0.830208</td>\n",
       "      <td>0.910664</td>\n",
       "      <td>0.921690</td>\n",
       "      <td>0.366668</td>\n",
       "      <td>0.511379</td>\n",
       "      <td>0.021467</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>0.951897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM989831</th>\n",
       "      <td>0.799606</td>\n",
       "      <td>0.882730</td>\n",
       "      <td>0.963902</td>\n",
       "      <td>0.909886</td>\n",
       "      <td>0.918864</td>\n",
       "      <td>0.939070</td>\n",
       "      <td>0.964011</td>\n",
       "      <td>0.923141</td>\n",
       "      <td>0.897723</td>\n",
       "      <td>0.604858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883601</td>\n",
       "      <td>0.098855</td>\n",
       "      <td>0.857063</td>\n",
       "      <td>0.891470</td>\n",
       "      <td>0.904103</td>\n",
       "      <td>0.407622</td>\n",
       "      <td>0.455352</td>\n",
       "      <td>0.021815</td>\n",
       "      <td>0.893462</td>\n",
       "      <td>0.939561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3231 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cg00320765  cg04223956  cg03407966  cg07403374  cg10122230  \\\n",
       "GSM989827    0.785241    0.906154    0.943392    0.945140    0.904783   \n",
       "GSM989828    0.811994    0.883670    0.937935    0.938376    0.929686   \n",
       "GSM989829    0.771808    0.893670    0.947600    0.915895    0.914621   \n",
       "GSM989830    0.800116    0.905407    0.930441    0.922973    0.891672   \n",
       "GSM989831    0.799606    0.882730    0.963902    0.909886    0.918864   \n",
       "\n",
       "           cg24603972  cg04105597  cg12613081  cg20169734  cg06012428  ...  \\\n",
       "GSM989827    0.925199    0.939552    0.927781    0.907609    0.562828  ...   \n",
       "GSM989828    0.930090    0.945331    0.927932    0.889046    0.494344  ...   \n",
       "GSM989829    0.917694    0.953757    0.901260    0.905771    0.538240  ...   \n",
       "GSM989830    0.923459    0.951738    0.899530    0.881363    0.533346  ...   \n",
       "GSM989831    0.939070    0.964011    0.923141    0.897723    0.604858  ...   \n",
       "\n",
       "           cg04820440  cg12662162  cg18527971  cg24367761  cg13027280  \\\n",
       "GSM989827    0.905512    0.113116    0.862678    0.920586    0.918897   \n",
       "GSM989828    0.858246    0.086961    0.839228    0.907824    0.893503   \n",
       "GSM989829    0.890826    0.124099    0.868137    0.891428    0.899440   \n",
       "GSM989830    0.902694    0.087692    0.830208    0.910664    0.921690   \n",
       "GSM989831    0.883601    0.098855    0.857063    0.891470    0.904103   \n",
       "\n",
       "           cg14801864  cg04984575  cg24836583  cg18079534  cg17362351  \n",
       "GSM989827    0.388287    0.492888    0.015052    0.879088    0.929998  \n",
       "GSM989828    0.302853    0.481399    0.022104    0.887265    0.920493  \n",
       "GSM989829    0.372548    0.510238    0.012122    0.899792    0.936039  \n",
       "GSM989830    0.366668    0.511379    0.021467    0.924791    0.951897  \n",
       "GSM989831    0.407622    0.455352    0.021815    0.893462    0.939561  \n",
       "\n",
       "[5 rows x 3231 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CpG_methylation = pd.read_csv('data/blood_top_CpGs.csv', index_col=0, header=0).drop(labels=\"age\", axis=1)\n",
    "\n",
    "print(\"Shape of Data Set: \")\n",
    "print()\n",
    "print(CpG_methylation.shape)\n",
    "print()\n",
    "CpG_methylation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GSM989827</th>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM989828</th>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM989829</th>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM989830</th>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSM989831</th>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              1\n",
       "0              \n",
       "GSM989827  67.0\n",
       "GSM989828  89.0\n",
       "GSM989829  66.0\n",
       "GSM989830  64.0\n",
       "GSM989831  62.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_ages = pd.read_csv(\"data/subject_ages.csv\", index_col=0, header=None)\n",
    "\n",
    "subject_ages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Plot the age distribution of subjects using a histogram. Add a vertical line to the plot at age 65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure,ax = plt.subplots(figsize=(10,5))\n",
    "ax.hist(subject_ages)\n",
    "ax.axvline(x=65,color='k', linestyle='dashed',linewidth=2)\n",
    "ax.set_xlabel('Age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Label subjects using two groups: \"youthful\" (ages <65) and \"aged\" (ages >=65). This age threshold divides the subjects into two groups of approximately equal size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "youthful = [\"youthful\" if age < 65 else \"aged\" for age in subject_ages.values.flatten()]\n",
    "# Young are 0, aged are 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Randomly assign 20% of samples in the data to a training set. Assign the remaining 80% of samples to a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131\n",
      "525\n",
      "131\n",
      "525\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(CpG_methylation, youthful, test_size=0.8, train_size=0.2, shuffle=True)\n",
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train an SVM and logistic regression classifier to predict age labels (\"youthful\" or \"aged\") for subjects in the training set based on CpG methylation levels. **Hint:** When training your SVM classifier, use a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annikalai/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#logistic regression\n",
    "logist_reg = LogisticRegression()\n",
    "svm_logist_reg = logist_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluate each classifier's performance on the test set by (a) identifying the classifier's accuracy and (b) generating a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy= 0.7790476190476191\n",
      "[[203  66]\n",
      " [ 50 206]]\n",
      "Log Reg Accuracy= 0.7676190476190476\n",
      "[[195  74]\n",
      " [ 48 208]]\n"
     ]
    }
   ],
   "source": [
    "#calc accuracy\n",
    "y_predict_svm = clf.predict(x_test)\n",
    "y_predict_reg = svm_logist_reg.predict(x_test)\n",
    "acc_svm = clf.score(x_test,y_test)\n",
    "acc_reg = svm_logist_reg.score(x_test,y_test)\n",
    "\n",
    "#calc confusion matrix\n",
    "CM_svm = confusion_matrix(y_test,y_predict_svm)\n",
    "CM_reg = confusion_matrix(y_test,y_predict_reg)\n",
    "print('SVM', 'Accuracy=', acc_svm)\n",
    "print(CM_svm)\n",
    "print('Log Reg', 'Accuracy=', acc_reg)\n",
    "print(CM_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What is the false positive rate of each classifier? What is the false negative rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier\n",
      "FP rate: 0.2426470588235294 FN rate: 0.1976284584980237\n",
      "Logistic Regression Classifier\n",
      "FP rate: 0.2624113475177305 FN rate: 0.19753086419753085\n"
     ]
    }
   ],
   "source": [
    "N_svm = CM_svm[0][1]+CM_svm[1][1]\n",
    "P_svm = CM_svm[0][0]+CM_svm[1][0]\n",
    "FP_svm = CM_svm[0][1]/N_svm\n",
    "FN_svm = CM_svm[1][0]/P_svm\n",
    "\n",
    "N_reg = CM_reg[0][1]+CM_reg[1][1]\n",
    "P_reg = CM_reg[0][0]+CM_reg[1][0]\n",
    "FP_reg = CM_reg[0][1]/N_reg\n",
    "FN_reg = CM_reg[1][0]/P_reg\n",
    "\n",
    "print(\"SVM Classifier\")\n",
    "print('FP rate:', FP_svm, 'FN rate:', FN_svm)\n",
    "print(\"Logistic Regression Classifier\")\n",
    "print('FP rate:', FP_reg, 'FN rate:', FN_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Repeat questions 3-6 for a 80%/20% train/test split. How does increasing the training set size affect classifier performance? What considerations would you make when specifying a train/test split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/annikalai/miniconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy= 0.8333333333333334\n",
      "[[51 14]\n",
      " [ 8 59]]\n",
      "Log Reg Accuracy= 0.8560606060606061\n",
      "[[56  9]\n",
      " [10 57]]\n",
      "SVM Classifier\n",
      "FP rate: 0.1917808219178082 FN rate: 0.13559322033898305\n",
      "Logistic Regression Classifier\n",
      "FP rate: 0.13636363636363635 FN rate: 0.15151515151515152\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(CpG_methylation, youthful, test_size=0.2, train_size=0.8, shuffle=True)\n",
    "#SVM\n",
    "clf = svm.SVC(kernel=\"linear\")\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#logistic regression\n",
    "logist_reg = LogisticRegression()\n",
    "svm_logist_reg = logist_reg.fit(x_train, y_train)\n",
    "\n",
    "#calc accuracy\n",
    "y_predict_svm = clf.predict(x_test)\n",
    "y_predict_reg = svm_logist_reg.predict(x_test)\n",
    "acc_svm = clf.score(x_test,y_test)\n",
    "acc_reg = svm_logist_reg.score(x_test,y_test)\n",
    "\n",
    "#calc confusion matrix\n",
    "CM_svm = confusion_matrix(y_test,y_predict_svm)\n",
    "CM_reg = confusion_matrix(y_test,y_predict_reg)\n",
    "print('SVM', 'Accuracy=', acc_svm)\n",
    "print(CM_svm)\n",
    "print('Log Reg', 'Accuracy=', acc_reg)\n",
    "print(CM_reg)\n",
    "\n",
    "N_svm = CM_svm[0][1]+CM_svm[1][1]\n",
    "P_svm = CM_svm[0][0]+CM_svm[1][0]\n",
    "FP_svm = CM_svm[0][1]/N_svm\n",
    "FN_svm = CM_svm[1][0]/P_svm\n",
    "\n",
    "N_reg = CM_reg[0][1]+CM_reg[1][1]\n",
    "P_reg = CM_reg[0][0]+CM_reg[1][0]\n",
    "FP_reg = CM_reg[0][1]/N_reg\n",
    "FN_reg = CM_reg[1][0]/P_reg\n",
    "\n",
    "print(\"SVM Classifier\")\n",
    "print('FP rate:', FP_svm, 'FN rate:', FN_svm)\n",
    "print(\"Logistic Regression Classifier\")\n",
    "print('FP rate:', FP_reg, 'FN rate:', FN_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the training set size improves the performace/accuracy of both classifiers. However, when deciding the relative training/test data split it is important to find a balance between a large enough training data set to train the model well, but also not too large as that could lead to overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
